# # -*- coding: utf-8 -*-
# """Collective_Final_Project.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1Z_vZ0LBt-wXQOVkd9XDdlMMhMhRrwmac
# """

# # Commented out IPython magic to ensure Python compatibility.
# import numpy as np
# import pandas as pd
# import seaborn as sns
# import matplotlib.pyplot as mlt
# import missingno as mno

# # %matplotlib inline

# pd.set_option('display.max_columns', None)
# pd.set_option('display.max_rows', 500)
# pd.set_option('display.max_columns', 500)
# pd.set_option('display.width', 1000)

# from google.colab import drive
# import pandas as pd

# # Mount Google Drive
# drive.mount('/content/drive')

# # Define the file path within the shared folder
# shared_folder_path = "/content/drive/My Drive/Data_Science_Final_Project/"

# # Concatenate the shared folder path with the file name
# file_path = shared_folder_path + "final_transactions_dataset.csv"

# # Read the CSV file
# df = pd.read_csv(file_path)

# """# **TEAM READ**

# #####*Update Notes - 17/04/2024*:


# *   I have looked over the some of the variables that may have some correlations. I thought there were some interesting patterns in some of the graphs and I think it's worth spending a bit more time on those graphs to see what is causing the relationships.
# * I was thinking we could also come up with a way to use more than one of the learning models we learned in class in order to apply the best learning model as possible. We can make a complex functionality that would look at what the majority data is and be able to compute whihc learning model would be the best for it.


# """

# df

# tech_df = df.loc[df['sector'] == 'TECH']
# tech_df = tech_df.sample(n=10000)

# # looking for NA Values
# print(tech_df.isna().sum())
# mno.matrix(tech_df, figsize = (20, 6))

# # sns.pairplot(tech_df) -- UNCOMMENT IF NEEDED, WILL TAKE TIME TO RUN

# sns.boxplot(tech_df['horizon (days)'])

# (tech_df['horizon (days)'] > 300).sum() # outliers

# cols = ['ESG_ranking', 'Volatility_Buy',  'Sharpe Ratio', 'inflation','PS_ratio','NetProfitMargin_ratio', 'PB_ratio', 'roa_ratio', 'roe_ratio','EPS_ratio'] # possible essential columns
# sns.pairplot(tech_df[cols])

# fig, axes = mlt.subplots(1, 2, figsize=(10, 4))

# # Plot the distribution plot
# sns.distplot(tech_df['Volatility_Buy'], ax=axes[0])
# axes[0].set_title('Volatility_Buy')

# # Plot the boxplot
# sns.distplot(tech_df['Volatility_sell'], ax=axes[1])
# axes[1].set_title('Votality_Sell')

# # Adjust layout
# mlt.tight_layout()

# # Show the plots
# mlt.show()

# # heat map


# corrMatrix = tech_df[cols].corr()

# sns.heatmap(corrMatrix, annot = True, cmap ='coolwarm', fmt='.2f')
# mlt.title('Heatmap Correlation')
# mlt.show()

# sns.boxplot(tech_df['ESG_ranking'])

# first_quartile = tech_df['ESG_ranking'].quantile(0.25)

# top_25_percent = tech_df[tech_df['ESG_ranking'] <= first_quartile]
# bottom_75_percent = tech_df[tech_df['ESG_ranking'] > first_quartile]

# bottom_75_percent

# # import streamlit as st
# # import pandas as pd
# # import numpy as np
# # import seaborn as sns
# # from PIL import Image
# # import matplotlib.pyplot as plt
# # from sklearn.model_selection import train_test_split
# # from sklearn.linear_model import LinearRegression
# # from sklearn import metrics


# # st.sidebar.header("Dashboard")
# # st.sidebar.markdown("---")
# # app_mode = st.sidebar.selectbox('Select Page',['Introduction','Visualization','Prediction'])

# # df = pd.read_csv("transactions_dataset.csv")



# # if app_mode == "Introduction":

# #   st.title("Introduction")
# #   st.markdown("### Welcome to our ESG rankings Dashboard!")

# #   #st.image("veh.jpeg", use_column_width=True)

# #   st.markdown("#### Wondering how ESG rankings truly effect company investment & returns?")
# #   st.markdown("Our goal is explore investments relative to ESG Rankings & finding/creating a positive feedback loop ")
# #   st.markdown("##### Objectives")
# #   st.markdown("- Using other variables that contribute to investment over the years")
# #   st.markdown("- Points that can be made: ESG growth over the years; correlation w Investment & social pressures")
# #   st.markdown("- Does ESG ranking positivley or negatively effect investments? ")

# #   num = st.number_input('No. of Rows', 5, 10)

# #   head = st.radio('View from top (head) or bottom (tail)', ('Head', 'Tail'))
# #   if head == 'Head':
# #     st.dataframe(df.head(num))
# #   else:
# #     st.dataframe(df.tail(num))

# #   st.text('(Rows,Columns)')
# #   st.write(df.shape)

# #   st.markdown("##### Key Variables")

# #   st.dataframe(df.describe())

# #   st.markdown("### Missing Values")
# #   st.markdown("Null or NaN values.")

# #   dfnull = df.isnull().sum()/len(df)*100
# #   totalmiss = dfnull.sum().round(2)
# #   st.write("Percentage of total missing values:",totalmiss)
# #   st.write(dfnull)
# #   if totalmiss <= 30:
# #     st.success("We have less then 30 percent of missing values, which is good. This provides us with more accurate data as the null values will not significantly affect the outcomes of our conclusions. And no bias will steer towards misleading results. ")
# #   else:
# #     st.warning("Poor data quality due to greater than 30 percent of missing value.")
# #     st.markdown(" > Theoretically, 25 to 30 percent is the maximum missing values are allowed, there's no hard and fast rule to decide this threshold. It can vary from problem to problem.")

# #   st.markdown("### Completeness")
# #   st.markdown(" The ratio of non-missing values to total records in dataset and how comprehensive the data is.")

# #   st.write("Total data length:", len(df))
# #   nonmissing = (df.notnull().sum().round(2))
# #   completeness= round(sum(nonmissing)/len(df),2)

# #   st.write("Completeness ratio:",completeness)
# #   st.write(nonmissing)
# #   if completeness >= 0.80:
# #     st.success("We have completeness ratio greater than 0.85, which is good. It shows that the vast majority of the data is available for us to use and analyze. ")
# #   else:
# #     st.success("Poor data quality due to low completeness ratio( less than 0.85).")

# # elif app_mode == "Visualization":
# #   st.title("Visualization")
# #   tech_df = df.loc[df['sector'] == 'TECH']



# #   # DATA VISUALISATION
# #   tab1, tab2, tab3, tab4 = st.tabs(["SNS Plot", "Bar Chart", "Line Chart", "Pie Plot"])

# #   #SNS plot
# #   tab1.subheader("SNS plot")
# #   tech_df = tech_df.sample(n=10000)
# #   fig = sns.pairplot(tech_df)
# #   tab1.pyplot(fig)

# #   #Bar Graph
# #   # User input for x-variable
# #   columns = ['Region_Code', 'Gender', 'Vehicle_Age']
# #   x_variable = tab2.selectbox("Select x-variable:", columns)
# #   tab2.subheader(f"{x_variable} vs Price (INR)")
# #   #data_by_variable = df.groupby(x_variable)['Annual_Premium'].mean()
# #   #tab2.bar_chart(data_by_variable)

# #   #Line Graph
# #   tab3.subheader("Age vs Price")
# #   #age_by_price = df.groupby('Age')['Annual_Premium'].mean()
# #   #tab3.line_chart(age_by_price)

# #   '''
# #   tab4.subheader("Pie plot")
# #   tab4.subheader("Response distribution by Vehicle Damage")
# #   response_counts = df.groupby(['Vehicle_Damage', 'Response']).size().unstack(fill_value=0)
# #   fig, ax = plt.subplots()
# #   colors = ['#ff9999','#66b3ff']
# #   damage_counts = response_counts.loc[1]
# #   percentages = (damage_counts.values / damage_counts.sum()) * 100
# #   labels = ['Yes', 'No']
# #   ax.pie(percentages, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
# #   ax.axis('equal')
# #   tab4.pyplot(fig)

# #   #Pie Plot2
# #   tab4.subheader("Response Distribution by Not Previously Insured")
# #   response_counts = df.groupby(['Previously_Insured', 'Response']).size().unstack(fill_value=0)
# #   fig, ax = plt.subplots()
# #   colors = ['#ff9999','#66b3ff']
# #   prev_insurance_counts = response_counts.loc[0]
# #   percentages = (prev_insurance_counts.values / prev_insurance_counts.sum()) * 100
# #   labels = ['Yes', 'No']
# #   ax.pie(percentages, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
# #   ax.axis('equal')
# #   tab4.pyplot(fig)


# #   tab1, tab2, tab3, tab4 = st.tabs(["SNS Plot", "Bar Chart", "Line Chart", "Pie Plot"])

# #   fig = sns.pairplot(df)
# #   tab1.pyplot(fig)
# #   '''

# # elif app_mode == "Prediction":
# #   st.markdown("Prediction")

# #   '''
# #   # Changing "Yes" and "No" to 1 and 0
# #   df.loc[df['Vehicle_Damage'] == "Yes", 'Vehicle_Damage'] = 1
# #   df.loc[df['Vehicle_Damage'] == "No", 'Vehicle_Damage'] = 0
# #   st.title("Prediction")
# #   X = df[['Age', 'Region_Code', 'Driving_License','Vehicle_Damage', 'Previously_Insured']]
# #   y = df['Annual_Premium']
# #   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# #   lin_reg = LinearRegression()
# #   lin_reg.fit(X_train,y_train)
# #   pred = lin_reg.predict(X_test)

# #   plt.figure(figsize=(10,7))
# #   plt.title("Actual vs. predicted Annual Premiums",fontsize=25)
# #   plt.xlabel("Actual test set Annual Premiums",fontsize=18)
# #   plt.ylabel("Predicted Annual Premiums", fontsize=18)
# #   plt.scatter(x=y_test,y=pred)
# #   plt.savefig('prediction.png')
# #   st.image('prediction.png')

# #   # Model Evaluation
# #   st.markdown("Evaluation")
# #   coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])
# #   st.dataframe(coeff_df)
# #   MAE = metrics.mean_absolute_error(y_test, pred)
# #   MSE = metrics.mean_squared_error(y_test, pred)
# #   RMSE = np.sqrt(metrics.mean_squared_error(y_test, pred))
# #   st.write('MAE:', MAE)
# #   st.write('MSE:', MSE)
# #   st.write('RMSE:', RMSE)
# #   '''

# """MLFLOW B)"""

# # Commented out IPython magic to ensure Python compatibility.
# # %%capture
# # !pip install mlflow
# # !pip install pyngrok

# !killall ngrok

# import mlflow
# import mlflow.sklearn
# import subprocess
# from pyngrok import ngrok, conf
# import getpass

# import numpy as np
# import pandas as pd
# #from sklearn.datasets import load_boston
# from sklearn.model_selection import train_test_split, GridSearchCV
# from sklearn.linear_model import LinearRegression
# from sklearn.tree import DecisionTreeRegressor
# from sklearn.metrics import mean_squared_error, r2_score

# MLFLOW_TRACKING_URI = "sqlite:///mlflow.db"
# subprocess.Popen(["mlflow", "ui", "--backend-store-uri", MLFLOW_TRACKING_URI])
# mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

# mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
# mlflow.set_experiment("sklearn2")

# print("Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth")
# conf.get_default().auth_token = getpass.getpass()
# port=5000
# public_url = ngrok.connect(port).public_url
# print(f' * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:{port}\"')

# import mlflow
# from mlflow import log_metric, log_param, log_artifact
# from sklearn.datasets import load_iris
# from sklearn.model_selection import train_test_split, GridSearchCV
# from sklearn.tree import DecisionTreeClassifier
# import joblib

# with mlflow.start_run():

#     # Load dataset
#     iris = load_iris()
#     X, y = iris.data, iris.target

#     # Split the data into training and testing sets
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#     # Create a decision tree classifier
#     dt = DecisionTreeClassifier(random_state=42)

#     # Define a parameter grid to search over
#     param_grid = {'max_depth': [3, 5, 10], 'min_samples_leaf': [1, 2, 4]}

#     # Create GridSearchCV object
#     grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5)

#     # Perform grid search to find the best parameters
#     grid_search.fit(X_train, y_train)

#     # Log the best parameters
#     best_params = grid_search.best_params_
#     mlflow.log_params(best_params)

#     # Evaluate the model
#     best_dt = grid_search.best_estimator_
#     test_score = best_dt.score(X_test, y_test)

#     # Log the performance metric
#     accuracy = accuracy_score(y_test, y_pred)
#     precision = precision_score(y_test, y_pred)
#     recall = recall_score(y_test, y_pred)
#     f1 = f1_score(y_test, y_pred)

#     log_metric("accuracy", accuracy)
#     log_metric("precision", precision)
#     log_metric("recall", recall)
#     log_metric("f1", f1)


#     print(f"Accuracy: {accuracy}")
#     print(f"Precision: {precision}")
#     print(f"Recall: {recall}")
#     print(f"F1 Score: {f1}")
#     # Log the best model in MLflow
#     mlflow.sklearn.log_model(best_dt, "best_dt")

#     # Save the model to the MLflow artifact store
#     mlflow.sklearn.save_model(best_dt, "best_dt_model")

# import mlflow
# logged_model = 'runs:/97f1d68e0895405c8948d8ec3c504551/best_dt'

# # Load model as a PyFuncModel.
# loaded_model = mlflow.pyfunc.load_model(logged_model)

# # Predict on a Pandas DataFrame.
# import pandas as pd
# predictions = loaded_model.predict(pd.DataFrame(X_test))

# # from sklearn.metrics import accuracy_score
# # # Calculate the accuracy comparing the predicted labels with the true labels
# # accuracy = accuracy_score(y_test, predictions)

# """linear regression"""

# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LinearRegression
# from sklearn.metrics import mean_squared_error, r2_score
# import pandas as pd
# from sklearn.preprocessing import LabelEncoder
# import seaborn as sns
# import matplotlib.pyplot as plt

# # Assuming df is your DataFrame containing all variables
# # df = pd.read_csv("transactions_dataset.csv")
# #variables = df.columns
# cols = ['ESG_ranking', 'Volatility_Buy',  'Sharpe Ratio', 'inflation','PS_ratio','NetProfitMargin_ratio', 'PB_ratio', 'roa_ratio', 'roe_ratio','EPS_ratio'] # possible essential columns
# temp_df = df[cols]
# # Get list of all variable names
# label_encoder = LabelEncoder()
# for name in list(cols):
#   temp_df[name] = label_encoder.fit_transform(temp_df[name])

# #for target_variable in variables:
# for target_variable in cols:
#     # Select the target variable for prediction
#     y = temp_df[target_variable]

#     # Select predictors (all other variables except the target variable)
#     X = temp_df.drop(columns=[target_variable])

#     # Split the data into training and testing sets
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#     # Fit linear regression model
#     model = LinearRegression()
#     model.fit(X_train, y_train)

#     # Make predictions
#     y_pred = model.predict(X_test)

#     # Calculate accuracy metrics
#     mse = mean_squared_error(y_test, y_pred)
#     r2 = r2_score(y_test, y_pred)

#     # Create a DataFrame to store actual and predicted values
#     results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

#     # Plot actual vs. predicted values using Seaborn
#     sns.scatterplot(x='Actual', y='Predicted', data=results_df)
#     plt.title(f'Actual vs. Predicted for {target_variable}')
#     plt.xlabel('Actual')
#     plt.ylabel('Predicted')

#     # Add a regression line
#     sns.regplot(x='Actual', y='Predicted', data=results_df, scatter=False, color='red')

#     plt.show()

#     print(f"Prediction of {target_variable} against all other variables:")
#     print(f"Mean Squared Error: {mse}")
#     print(f"R-squared: {r2}")
#     print("------------------------------------")

# !pip install shapash --quiet
# !pip install mlflow --quiet
# !pip install pyngrok --quiet
# !pip install scikit-learn==0.22 --quiet

# """Decision Tree"""

# import pandas as pd
# from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
# from sklearn.model_selection import train_test_split # Import train_test_split function
# from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
# import matplotlib.pyplot as plt
# from sklearn.preprocessing import LabelEncoder
# import graphviz
# from sklearn.tree import export_graphviz

# # df = pd.read_csv("transactions_dataset.csv")
# '''
# ## replace missing value with mean value of column
# loan.fillna(loan.mean(), inplace=True)  # For numerical columns
# loan['Loan_Status'].fillna(loan['Loan_Status'].mode()[0], inplace=True)  # For a categorical column
# '''
# cols = ['ESG_ranking', 'Volatility_Buy',  'Sharpe Ratio', 'inflation','PS_ratio','NetProfitMargin_ratio', 'PB_ratio', 'roa_ratio', 'roe_ratio','EPS_ratio'] # possible essential columns
# temp_df = df[cols].copy()
# label_encoder = LabelEncoder()
# for name in cols:
#   temp_df[name] = label_encoder.fit_transform(temp_df[name])

# X = temp_df.drop(["NetProfitMargin_ratio"],axis=1)
# y = temp_df.NetProfitMargin_ratio # Target variable

# #Split dataset into training set and test set
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

# # Create Decision Tree classifer object
# clf = DecisionTreeClassifier()
# #clf = DecisionTreeClassifier(max_depth=3)


# # Train Decision Tree Classifer
# clf = clf.fit(X_train,y_train)

# #Predict the response for test dataset
# y_pred = clf.predict(X_test)

# # Model Accuracy, how often is the classifier correct?
# print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# feature_names = X.columns
# feature_cols = X.columns
# dot_data = export_graphviz(clf, out_file=None, feature_names=feature_cols, filled=True, rounded=True, special_characters=True)

# graph = graphviz.Source(dot_data)
# graph

# from shapash.explainer.smart_explainer import SmartExplainer
# xpl = SmartExplainer(clf)
# y_pred = pd.Series(y_pred)
# X_test = X_test.reset_index(drop=True)
# xpl.compile(x=X_test, y_pred=y_pred)
# xpl.plot.features_importance()

# """Streamlit"""

# import streamlit as st
# import pandas as pd
# import numpy as np
# import seaborn as sns
# from PIL import Image
# import matplotlib.pyplot as plt
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LinearRegression
# from sklearn import metrics

# st.sidebar.header("Dashboard")
# st.sidebar.markdown("---")
# app_mode = st.sidebar.selectbox('Select Page',['Introduction','Visualization','Prediction'])

# df = pd.read_csv("transactions_dataset.csv")
# tech_df = df.loc[df['sector'] == 'TECH']



# if app_mode == "Introduction":

#   st.title("Introduction")
#   st.markdown("### Welcome to our ESG rankings Dashboard!")

#   #st.image("veh.jpeg", use_column_width=True)

#   st.markdown("#### Wondering how ESG rankings truly effect company investment & returns?")
#   st.markdown("Our goal is explore investments relative to ESG Rankings & finding/creating a positive feedback loop ")
#   st.markdown("##### Objectives")
#   st.markdown("- Using other variables that contribute to investment over the years")
#   st.markdown("- Points that can be made: ESG growth over the years; correlation w Investment & social pressures")
#   st.markdown("- Does ESG ranking positivley or negatively effect investments? ")

#   num = st.number_input('No. of Rows', 5, 10)

#   head = st.radio('View from top (head) or bottom (tail)', ('Head', 'Tail'))
#   if head == 'Head':
#     st.dataframe(df.head(num))
#   else:
#     st.dataframe(df.tail(num))

#   st.text('(Rows,Columns)')
#   st.write(df.shape)

#   st.markdown("##### Key Variables")

#   st.dataframe(df.describe())

#   st.markdown("### Missing Values")
#   st.markdown("Null or NaN values.")

#   dfnull = df.isnull().sum()/len(df)*100
#   totalmiss = dfnull.sum().round(2)
#   st.write("Percentage of total missing values:",totalmiss)
#   st.write(dfnull)
#   if totalmiss <= 30:
#     st.success("We have less then 30 percent of missing values, which is good. This provides us with more accurate data as the null values will not significantly affect the outcomes of our conclusions. And no bias will steer towards misleading results. ")
#   else:
#     st.warning("Poor data quality due to greater than 30 percent of missing value.")
#     st.markdown(" > Theoretically, 25 to 30 percent is the maximum missing values are allowed, there's no hard and fast rule to decide this threshold. It can vary from problem to problem.")

#   st.markdown("### Completeness")
#   st.markdown(" The ratio of non-missing values to total records in dataset and how comprehensive the data is.")

#   st.write("Total data length:", len(df))
#   nonmissing = (df.notnull().sum().round(2))
#   completeness= round(sum(nonmissing)/len(df),2)

#   st.write("Completeness ratio:",completeness)
#   st.write(nonmissing)
#   if completeness >= 0.80:
#     st.success("We have completeness ratio greater than 0.85, which is good. It shows that the vast majority of the data is available for us to use and analyze. ")
#   else:
#     st.success("Poor data quality due to low completeness ratio( less than 0.85).")

# elif app_mode == "Visualization":
#   st.title("Visualization")




#   # DATA VISUALISATION
#   tab1, tab2, tab3, tab4 = st.tabs(["SNS Plot", "Bar Chart", "Line Chart", "Pie Plot"])

#   #SNS plot
#   tab1.subheader("SNS plot")
#   tech_df = tech_df.sample(n=10000)
#   fig = sns.pairplot(tech_df)
#   tab1.pyplot(fig)

#   #Bar Graph
#   # User input for x-variable
#   columns = ['Region_Code', 'Gender', 'Vehicle_Age']
#   x_variable = tab2.selectbox("Select x-variable:", columns)
#   tab2.subheader(f"{x_variable} vs Price (INR)")
#   #data_by_variable = df.groupby(x_variable)['Annual_Premium'].mean()
#   #tab2.bar_chart(data_by_variable)

#   #Line Graph
#   tab3.subheader("Age vs Price")
#   #age_by_price = df.groupby('Age')['Annual_Premium'].mean()
#   #tab3.line_chart(age_by_price)

#   '''
#   tab4.subheader("Pie plot")
#   tab4.subheader("Response distribution by Vehicle Damage")
#   response_counts = df.groupby(['Vehicle_Damage', 'Response']).size().unstack(fill_value=0)
#   fig, ax = plt.subplots()
#   colors = ['#ff9999','#66b3ff']
#   damage_counts = response_counts.loc[1]
#   percentages = (damage_counts.values / damage_counts.sum()) * 100
#   labels = ['Yes', 'No']
#   ax.pie(percentages, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
#   ax.axis('equal')
#   tab4.pyplot(fig)

#   #Pie Plot2
#   tab4.subheader("Response Distribution by Not Previously Insured")
#   response_counts = df.groupby(['Previously_Insured', 'Response']).size().unstack(fill_value=0)
#   fig, ax = plt.subplots()
#   colors = ['#ff9999','#66b3ff']
#   prev_insurance_counts = response_counts.loc[0]
#   percentages = (prev_insurance_counts.values / prev_insurance_counts.sum()) * 100
#   labels = ['Yes', 'No']
#   ax.pie(percentages, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
#   ax.axis('equal')
#   tab4.pyplot(fig)


#   tab1, tab2, tab3, tab4 = st.tabs(["SNS Plot", "Bar Chart", "Line Chart", "Pie Plot"])

#   fig = sns.pairplot(df)
#   tab1.pyplot(fig)
#   '''

# elif app_mode == "Prediction":
#   st.markdown("Prediction")

#   '''
#   # Changing "Yes" and "No" to 1 and 0
#   df.loc[df['Vehicle_Damage'] == "Yes", 'Vehicle_Damage'] = 1
#   df.loc[df['Vehicle_Damage'] == "No", 'Vehicle_Damage'] = 0
#   st.title("Prediction")
#   X = df[['Age', 'Region_Code', 'Driving_License','Vehicle_Damage', 'Previously_Insured']]
#   y = df['Annual_Premium']
#   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#   lin_reg = LinearRegression()
#   lin_reg.fit(X_train,y_train)
#   pred = lin_reg.predict(X_test)

#   plt.figure(figsize=(10,7))
#   plt.title("Actual vs. predicted Annual Premiums",fontsize=25)
#   plt.xlabel("Actual test set Annual Premiums",fontsize=18)
#   plt.ylabel("Predicted Annual Premiums", fontsize=18)
#   plt.scatter(x=y_test,y=pred)
#   plt.savefig('prediction.png')
#   st.image('prediction.png')

#   # Model Evaluation
#   st.markdown("Evaluation")
#   coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])
#   st.dataframe(coeff_df)
#   MAE = metrics.mean_absolute_error(y_test, pred)
#   MSE = metrics.mean_squared_error(y_test, pred)
#   RMSE = np.sqrt(metrics.mean_squared_error(y_test, pred))
#   st.write('MAE:', MAE)
#   st.write('MSE:', MSE)
#   st.write('RMSE:', RMSE)
#   '''

# """# Exploratory Data Analysis


# *   Explore the shape and see what type of problem you are solving.
# *   Define the problem and shape of the dataet.
# *   **Look for outliers if any and see its distribution across the columns, along the columns.**
# *   What type of null you have (Categorical or Numerical).
# *   How would fix the null values.

# # Visualization

# Analyse the data, try to come up with some intereszting and Insightful visualization.

# Come up with different analysis and what do you infer and observe from it:
# - **Univariate Analysis of all the Variables**
# - **Bi-variate analysis of atleast 3 pair of variables/features**
#    1.   Categorical Vs Categorical
#    2.   Categorical Vs Numerical
#    3.   Numerical Vs Numerical
# - **Multi-variate analysis**
# - Plot some Pie-Chart as well.
# - Some box-plots as well.

# # Modelling


# Build a model that can categorizes restaurants into 'Budget' and 'Expensive' and identify how different features influence the decision. Please explain the findings effectively for technical and non-technical audiences using comments and visualizations, if appropriate.
# - **Build an optimized model that effectively solves the business problem.**
# - **The model will be evaluated on the basis of Accuracy.**
# - **Read the test.csv file and prepare features for testing.**
# """


